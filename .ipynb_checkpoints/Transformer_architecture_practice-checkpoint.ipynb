{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00a8372d-c1a0-44d8-b93a-11980665da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "78cb9119-951b-4bfa-aaf6-b56cb8d8d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "EMBEDDING_DIM = 726\n",
    "BLOCK_SIZE = 16\n",
    "N_HEADS = 4\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceacb266-39e1-44f8-b64c-5f5e953c471c",
   "metadata": {},
   "source": [
    "# Loading text and removing unnecessary characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae272457-3085-4c27-9e45-0443ecd2966c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "remove = ['-', '$', '&']\n",
    "for rm in remove:\n",
    "    text = text.replace(rm, '')\n",
    "words = text.split()\n",
    "\n",
    "VOCAB_SIZE = len(set(words))\n",
    "vocab = sorted(list(set(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1ddaa2e3-f9c3-4e39-a776-44be88c0e70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25454"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe86d244-5a30-4970-9abc-74711e4f5e49",
   "metadata": {},
   "source": [
    "# Training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9747c24-86c6-4b48-a1e8-d2796761b0bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_int = {word:idx for idx, word in enumerate(vocab)}\n",
    "int_vocab = {idx:word for idx, word in enumerate(vocab)}\n",
    "\n",
    "word_to_int_array = [vocab_int[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81938cf7-271f-4373-b6a4-2ffb5d6e4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_size = len(words)\n",
    "inputs = list()\n",
    "targets = list()\n",
    "for i in range(10000):\n",
    "    start = numpy.random.randint(1,\n",
    "                                 list_size - BLOCK_SIZE - 1\n",
    "                                )\n",
    "    inputs.append(word_to_int_array[start:start+BLOCK_SIZE])\n",
    "    targets.append(word_to_int_array[start+BLOCK_SIZE+1])\n",
    "\n",
    "\n",
    "inputs = torch.tensor(inputs, \n",
    "                      dtype = torch.long, \n",
    "                      device = device\n",
    "                     )\n",
    "targets = torch.tensor(targets, \n",
    "                       dtype = torch.long, \n",
    "                       device = device\n",
    "                      )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03758829-d5d7-450a-9821-44c76c24d0ab",
   "metadata": {},
   "source": [
    "# Transformer Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79cd33-319c-4e2c-ac58-3cbe02ab7059",
   "metadata": {},
   "source": [
    "## Embedding block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "872ab86b-eb30-4aeb-bea8-20b82c24fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Embedding Block:\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    vocab_size(int): Size of vocabulary of document\n",
    "    embd(int): Size of embedding dimension\n",
    "    block_size(int): Number of elements in each row of input\n",
    "\n",
    "    Description:\n",
    "    ------------\n",
    "\n",
    "    To represent each number(word) with a unique sequence of numbers\n",
    "    which the computer can understand. Along with this, positional \n",
    "    information is also represented in the same higher dimension and \n",
    "    added to the embedding tensor.\n",
    "\n",
    "    Input dim: B,T\n",
    "    Output dim: B,T,H (H = embedding dimension)\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embd, block_size):\n",
    "        super().__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings = vocab_size, \n",
    "                                            embedding_dim =  embd\n",
    "                                           )\n",
    "        # Positional embedding layer\n",
    "        self.pos_layer = nn.Embedding(num_embeddings = block_size, \n",
    "                                      embedding_dim = embd\n",
    "                                     )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        embeddings = self.embedding_layer(x)\n",
    "        pos = self.pos_layer(torch.arange(T, \n",
    "                                          device = device))\n",
    "        token_embd = embeddings + pos\n",
    "\n",
    "        return token_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "784afd92-c52a-4691-b9af-482e2241992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = EmbeddingBlock(vocab_size = VOCAB_SIZE, embd = EMBEDDING_DIM, block_size = BLOCK_SIZE)\n",
    "m.to(device)\n",
    "temp = m(inputs[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d745d272-9470-4bab-a350-278da57c8c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16]) torch.Size([3, 16, 25454])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0:3].shape, temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b70001-d987-4c7a-8f77-1a42179567ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51b4b45d-4893-4810-bc06-f560d0613864",
   "metadata": {},
   "source": [
    "## Encoder Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956eea67-88cd-43eb-aa78-bf2bcfd7ce50",
   "metadata": {},
   "source": [
    "### Multi-Head Attention Block\n",
    "\n",
    "Head Block -> Multi-Head Block(Feed Forward Block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99adcf6e-023d-48f9-8639-e35f6cfca9cf",
   "metadata": {},
   "source": [
    "#### Feed Forward Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1e72421-feeb-492e-834f-01e4f821a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb966fe5-c849-43a0-a6f7-5ec405f0efc2",
   "metadata": {},
   "source": [
    "#### Head Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0e8b735-6d03-4029-85f7-ce6f3f59d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Head Block:\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    Description:\n",
    "    ------------\n",
    "\n",
    "    Core block of Transformer. Here is where the attention mechanism\n",
    "    is implemented. This is a single \"head\" of the transformer. In the\n",
    "    Multi-Head block a number of these heads are created and each learns\n",
    "    different information about the text.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d42fa7-7a2a-4776-b190-b778e7b8d682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c90d725c-ef5c-4246-99a6-74d094762a80",
   "metadata": {},
   "source": [
    "#### Multi-Head Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c5beb4e-150b-49ec-bea5-90152d78de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Block:\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    Description:\n",
    "    ------------\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9e066-cf53-4e08-ad55-4e87fdff91bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d69104d7-dcef-4b15-a863-7219f991a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder Block:\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "\n",
    "    Description:\n",
    "    ------------\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316d084-b736-4170-bcc8-2c5008d12cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "481263c1-6221-4d6e-9305-73cbcdf1d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    vocab_size(int): Size of vocabulary of document\n",
    "    embd(int): Size of embedding dimension\n",
    "    block_size(int): Number of elements in each row of input\n",
    "\n",
    "    Description:\n",
    "    ------------\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embd, block_size):\n",
    "        super().__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding_layer = EmbeddingBlock(vocab_size = vocab_size, embd = embd, block_size = block_size)\n",
    "        # Linear head layer\n",
    "        self.lm_head = nn.Linear(in_features = embd, out_features = vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9d8d036b-ef1c-4c14-a3cd-cb652aab543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = GPTModel(vocab_size = VOCAB_SIZE, embd = EMBEDDING_DIM, block_size = BLOCK_SIZE)\n",
    "g.to(device)\n",
    "temp = g(inputs[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "decc3e87-6b7a-4d8e-8059-fc139669d097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16]) torch.Size([1, 16, 25454])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0:1].shape, temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f387afa5-9796-48ac-9504-5675d1a41f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
